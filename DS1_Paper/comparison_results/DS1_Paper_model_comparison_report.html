
    <!DOCTYPE html>
    <html>
    <head>
        <title>Model Comparison Report</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
            h1, h2, h3 { color: #333; }
            .container { max-width: 1200px; margin: 0 auto; }
            table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }
            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
            th { background-color: #f2f2f2; }
            tr:nth-child(even) { background-color: #f9f9f9; }
            .best { font-weight: bold; color: green; }
            .worse { color: #666; }
            .summary { background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Model Comparison Report: All Approaches</h1>
            
            <div class="summary">
                <h2>Executive Summary</h2>
    
                <p>Based on 7 comparative metrics:</p>
                <ul>
                    <li>LLM approach (with keyword extraction) wins on 2 metrics</li>
                    <li>Traditional approach wins on 1 metrics</li>
                    <li>No-Tagging approach (direct document-to-label) wins on 2 metrics</li>
                    <li>Summarization approach (summarize → extract → label) wins on 2 metrics</li>
                    <li>Overall recommendation: <strong>Tie</strong></li>
                </ul>
            </div>
            
            <h2>Key Metrics Comparison</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>No-Tagging</th>
                    <th>Summarization</th>
                    <th>Best Model</th>
                </tr>
    
                <tr>
                    <td>Overall Density</td>
                    <td class="worse">0.0501</td>
                    <td class="best">0.1652</td>
                    <td class="worse">0.1300</td>
                    <td class="worse">0.0946</td>
                    <td>Traditional</td>
                </tr>
            
                <tr>
                    <td>Overall Distinctiveness</td>
                    <td class="worse">0.4721</td>
                    <td class="worse">0.2124</td>
                    <td class="worse">0.5174</td>
                    <td class="best">0.5319</td>
                    <td>Summary</td>
                </tr>
            
                <tr>
                    <td>Coherence C V</td>
                    <td class="best">0.3564</td>
                    <td class="worse">0.3317</td>
                    <td class="worse">0.3551</td>
                    <td class="worse">0.3328</td>
                    <td>Llm</td>
                </tr>
            
                <tr>
                    <td>Coherence C Uci</td>
                    <td class="worse">-0.3546</td>
                    <td class="worse">-0.1743</td>
                    <td class="best">-0.1680</td>
                    <td class="worse">-0.4720</td>
                    <td>No Tagging</td>
                </tr>
            
                <tr>
                    <td>Coherence C Npmi</td>
                    <td class="worse">-0.0133</td>
                    <td class="worse">-0.0195</td>
                    <td class="best">-0.0093</td>
                    <td class="worse">-0.0216</td>
                    <td>No Tagging</td>
                </tr>
            
                <tr>
                    <td>Overlap Quality Index</td>
                    <td class="worse">0.0864</td>
                    <td class="worse">0.0279</td>
                    <td class="worse">0.0850</td>
                    <td class="best">0.1126</td>
                    <td>Summary</td>
                </tr>
            
                <tr>
                    <td>Label Entropy</td>
                    <td class="best">3.3249</td>
                    <td class="worse">2.1890</td>
                    <td class="worse">2.4817</td>
                    <td class="worse">2.7774</td>
                    <td>Llm</td>
                </tr>
            
                <tr>
                    <td>Avg Labels Per Doc</td>
                    <td>1.4000</td>
                    <td>1.9000</td>
                    <td>1.1000</td>
                    <td>1.3000</td>
                    <td>More labels is not necessarily better, depends on use case</td>
                </tr>
            
            </table>
            
            <h2>Label and Document Counts</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>No-Tagging</th>
                    <th>Summarization</th>
                </tr>
    
            <tr>
                <td>Label Count</td>
                <td>11</td>
                <td>5</td>
                <td>6</td>
                <td>8</td>
            </tr>
        
            <tr>
                <td>Doc Count</td>
                <td>10</td>
                <td>10</td>
                <td>10</td>
                <td>10</td>
            </tr>
        
            </table>
            
            <h2>Label Quality Analysis</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>No-Tagging</th>
                    <th>Summarization</th>
                    <th>Best Model</th>
                </tr>
    
            <tr>
                <td>Avg Label Density</td>
                <td class="worse">0.0501</td>
                <td class="best">0.1652</td>
                <td class="worse">0.1300</td>
                <td class="worse">0.0946</td>
                <td>Traditional</td>
            </tr>
        
            <tr>
                <td>Avg Label Distinctiveness</td>
                <td class="worse">0.4721</td>
                <td class="worse">0.2124</td>
                <td class="worse">0.5174</td>
                <td class="best">0.5319</td>
                <td>Summary</td>
            </tr>
        
            </table>
            
            <h2>Approach Descriptions</h2>
            <table>
                <tr>
                    <th>Approach</th>
                    <th>Description</th>
                </tr>
                <tr>
                    <td>LLM</td>
                    <td>Extract keywords from full documents using LLM, then generate labels from those keywords.</td>
                </tr>
                <tr>
                    <td>Traditional</td>
                    <td>Use BERTopic or similar statistical approach to generate topics from document embeddings.</td>
                </tr>
                <tr>
                    <td>No-Tagging</td>
                    <td>Send documents directly to LLM to generate labels without intermediate keyword extraction.</td>
                </tr>
                <tr>
                    <td>Summarization</td>
                    <td>First summarize documents using LLM, then extract keywords from summaries, then generate labels.</td>
                </tr>
            </table>
            
            <h2>Conclusion</h2>
    
            <p>The four approaches demonstrate comparable performance, with each excelling in different areas. 
            The choice between them would depend on the specific requirements of the application, 
            such as whether semantic coherence, cluster separation, processing efficiency, or some combination is most important.</p>
        
        </div>
    </body>
    </html>
    