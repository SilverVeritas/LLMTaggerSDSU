
    <!DOCTYPE html>
    <html>
    <head>
        <title>Model Comparison Report</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
            h1, h2, h3 { color: #333; }
            .container { max-width: 1200px; margin: 0 auto; }
            table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }
            th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
            th { background-color: #f2f2f2; }
            tr:nth-child(even) { background-color: #f9f9f9; }
            .better { font-weight: bold; color: green; }
            .worse { color: #666; }
            .images { display: flex; flex-wrap: wrap; justify-content: center; gap: 20px; margin: 20px 0; }
            .image-container { text-align: center; }
            .summary { background-color: #f0f8ff; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Model Comparison Report: LLM vs. Traditional Approach</h1>
            
            <div class="summary">
                <h2>Executive Summary</h2>
    
                <p>Based on 7 comparative metrics:</p>
                <ul>
                    <li>LLM approach wins on 5 metrics</li>
                    <li>Traditional approach wins on 2 metrics</li>
                    <li>Overall recommendation: <strong>LLM</strong></li>
                </ul>
            </div>
            
            <h2>Key Metrics Comparison</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>Difference</th>
                    <th>Better Model</th>
                </tr>
    
                <tr>
                    <td>Overall Density</td>
                    <td class="worse">0.0501</td>
                    <td class="better">0.1652</td>
                    <td>-0.1151</td>
                    <td>Traditional</td>
                </tr>
            
                <tr>
                    <td>Overall Distinctiveness</td>
                    <td class="better">0.4721</td>
                    <td class="worse">0.2124</td>
                    <td>0.2597</td>
                    <td>LLM</td>
                </tr>
            
                <tr>
                    <td>Coherence C V</td>
                    <td class="better">0.3564</td>
                    <td class="worse">0.3317</td>
                    <td>0.0248</td>
                    <td>LLM</td>
                </tr>
            
                <tr>
                    <td>Coherence C Uci</td>
                    <td class="worse">-0.3546</td>
                    <td class="better">-0.1743</td>
                    <td>-0.1803</td>
                    <td>Traditional</td>
                </tr>
            
                <tr>
                    <td>Coherence C Npmi</td>
                    <td class="better">-0.0133</td>
                    <td class="worse">-0.0195</td>
                    <td>0.0063</td>
                    <td>LLM</td>
                </tr>
            
                <tr>
                    <td>Overlap Quality Index</td>
                    <td class="better">0.0864</td>
                    <td class="worse">0.0279</td>
                    <td>0.0585</td>
                    <td>LLM</td>
                </tr>
            
                <tr>
                    <td>Label Entropy</td>
                    <td class="better">3.3249</td>
                    <td class="worse">2.1890</td>
                    <td>1.1359</td>
                    <td>LLM</td>
                </tr>
            
                <tr>
                    <td>Avg Labels Per Doc</td>
                    <td>1.4000</td>
                    <td>1.9000</td>
                    <td>-0.5000</td>
                    <td>More labels is not necessarily better, depends on use case</td>
                </tr>
            
            </table>
            
            <h2>Label and Document Counts</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>Difference</th>
                </tr>
    
            <tr>
                <td>Label Count</td>
                <td>11</td>
                <td>5</td>
                <td>6</td>
            </tr>
        
            <tr>
                <td>Doc Count</td>
                <td>10</td>
                <td>10</td>
                <td>0</td>
            </tr>
        
            </table>
            
            <h2>Label Quality Analysis</h2>
            <table>
                <tr>
                    <th>Metric</th>
                    <th>LLM</th>
                    <th>Traditional</th>
                    <th>Better Model</th>
                </tr>
    
            <tr>
                <td>Avg Label Density</td>
                <td class="worse">0.0501</td>
                <td class="better">0.1652</td>
                <td>Traditional</td>
            </tr>
        
            <tr>
                <td>Avg Label Distinctiveness</td>
                <td class="better">0.4721</td>
                <td class="worse">0.2124</td>
                <td>LLM</td>
            </tr>
        
            <tr>
                <td>Unique Top Words Count</td>
                <td class="better">10.0000</td>
                <td class="worse">6.0000</td>
                <td>LLM</td>
            </tr>
        
            </table>
            
            <h2>Visualizations</h2>
            <div class="images">
                <div class="image-container">
                    <img src="metrics_comparison.png" alt="Metrics Comparison" width="600">
                    <p>Comparison of Key Metrics</p>
                </div>
                <div class="image-container">
                    <img src="radar_comparison.png" alt="Radar Comparison" width="500">
                    <p>Normalized Metrics Comparison</p>
                </div>
                <div class="image-container">
                    <img src="wins_pie_chart.png" alt="Wins Distribution" width="400">
                    <p>Distribution of Better Performance</p>
                </div>
            </div>
            
            <h2>Detailed Model Information</h2>
            
            <h3>LLM Model Labels</h3>
            <ul>
    
            <li><strong>Explainable AI and Interpretability</strong> (20 documents) - Top words: the, of, a, and, to</li>
        
            <li><strong>Clustering and Explanations</strong> (20 documents) - Top words: the, of, 1, to, and</li>
        
            <li><strong>Fraud Detection and GANs</strong> (20 documents) - Top words: the, and, of, in, supply</li>
        
            <li><strong>Fuzzing and Testing in Large Systems</strong> (20 documents) - Top words: the, of, and, in, to</li>
        
            <li><strong>Deep Learning and Medical Applications</strong> (20 documents) - Top words: the, of, and, a, to</li>
        
            <li><strong>Large Language Models and Scientific Publishing</strong> (20 documents) - Top words: the, and, of, in, to</li>
        
            <li><strong>Information Retrieval and Mechanistic Interpretability</strong> (20 documents) - Top words: the, and, in, of, a</li>
        
            <li><strong>Activity Scheduling and Generative Models</strong> (20 documents) - Top words: 0, the, of, and, a</li>
        
            <li><strong>Domain-Informed Neural Networks and Epidemiology</strong> (20 documents) - Top words: the, a, of, in, and</li>
        
            <li><strong>Distributed Systems and Privacy</strong> (20 documents) - Top words: the, k, and, a, of</li>
        
            </ul>
            
            <h3>Traditional Model Labels</h3>
            <ul>
    
            <li><strong>cluster, risk, counterfactual</strong> (20 documents) - Top words: the, of, and, a, to</li>
        
            <li><strong>test, fuzzing, sandboxfuzz</strong> (20 documents) - Top words: the, and, of, in, a</li>
        
            <li><strong>activity, model, eeg</strong> (20 documents) - Top words: the, of, and, a, to</li>
        
            <li><strong>arxiv, language, text</strong> (20 documents) - Top words: the, and, of, in, to</li>
        
            <li><strong>ir, mechir, interpretability</strong> (20 documents) - Top words: the, of, and, a, to</li>
        
            </ul>
            
            <h2>Conclusion</h2>
    
            <p>The LLM-based approach demonstrates superior performance overall, particularly in metrics related to 
            semantic coherence and quality of clustering. This suggests that for this specific document set, 
            the language model's understanding of context and semantics provides more meaningful topic groupings.</p>
        
        </div>
    </body>
    </html>
    